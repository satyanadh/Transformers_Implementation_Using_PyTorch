{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fcf70907",
      "metadata": {
        "id": "fcf70907"
      },
      "source": [
        "#Part 1 -- Basic PyTorch tensors\n",
        "\n",
        "In deep learning, we depend heavily on optimized concurrent tensor manipulation instead of iterative algorithms in traditional programming. Here we will first guide you through a sequence of PyTorch tensor manipulation that will be needed. Note that tensors are just generalization of matrices from 2-dimensional to `N`-dimensional in layman's term. It is extremely important that you can manipulate tensors at ease."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9383b913",
      "metadata": {
        "id": "9383b913"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64fbe8fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64fbe8fe",
        "outputId": "34d7aa37-ca4f-43c7-d9e8-364ca0479e18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a3859737b30>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.manual_seed(42)  # this is to ensure deterministic behavior"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e24b2c",
      "metadata": {
        "id": "99e24b2c"
      },
      "source": [
        "## 1.1 Create a Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eded9ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eded9ec",
        "outputId": "6ee31a08-1cf9-4b92-fb95-8c31c9146b92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "t357 = torch.zeros(3, 5, 7)\n",
        "t357"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7ad71f5",
      "metadata": {
        "id": "c7ad71f5"
      },
      "source": [
        "## 1.2 Get the Shape of a Tensor\n",
        "\n",
        "You must be familiar with the terminology of PyTorch tensors as it could be ambiguous otherwise. A tensor is a multi-dimensional object, and the list of dimensions of a tensor is called its _shape_, which is an attribute of a tensor. The length of the shape is equal to the number of dimensions of the tensor. Each element in the shape corresponds to a dimension. In the above example, the shape of `t357` is `[3, 5, 7]`. The tensor has three dimensions. The first dimension has 3 elements, the second dimension has 5, and the third and last dimension has 7.\n",
        "\n",
        "Note that, under Python convention, `list[-1]` is equivalent to `list[N - 1]`, where `N` is the size of the list. This indexing convention allows you to access the last element of the list without knowing the size of the list (of course, as long as the list has at least one element). Similarly, `list[-2]` is equivalent to `list[N - 2]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be6decaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be6decaf",
        "outputId": "ed9df864-d0ad-4b4a-fdcd-2d58da38b43c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "t357.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a22e0f8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a22e0f8e",
        "outputId": "ef06a024-0b74-47c4-82bf-b10751795bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim #0 = 3\n",
            "dim #1 = 5\n",
            "dim #2 = 7\n",
            "dim #last = 7\n",
            "number of dimensions = 3\n"
          ]
        }
      ],
      "source": [
        "print(f'dim #0 = {t357.shape[0]}')\n",
        "print(f'dim #1 = {t357.shape[1]}')\n",
        "print(f'dim #2 = {t357.shape[2]}')\n",
        "print(f'dim #last = {t357.shape[-1]}')\n",
        "print(f'number of dimensions = {len(t357.shape)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e465f4",
      "metadata": {
        "id": "99e465f4"
      },
      "source": [
        "## 1.3 Create a Range (as a 1D tensor)\n",
        "\n",
        "Note that when you create a tensor, sometimes you may need to explicitly specify the type. In the following examples, we have two tensors, one created as a tensor of long integers (by default), and the other as a tensor of floats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4692f946",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4692f946",
        "outputId": "0ee49ede-9720-4c1c-c7b9-39273a60f83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r60 = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "        54, 55, 56, 57, 58, 59])\n",
            "\n",
            "r60.shape = torch.Size([60])\n",
            "----------------------------------------------------------------\n",
            "r60f = tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
            "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
            "        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
            "        42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54., 55.,\n",
            "        56., 57., 58., 59.])\n",
            "\n",
            "r60f.shape = torch.Size([60])\n"
          ]
        }
      ],
      "source": [
        "r60 = torch.arange(0, 60)\n",
        "print(f'r60 = {r60}')\n",
        "print()\n",
        "print(f'r60.shape = {r60.shape}')\n",
        "print('----------------------------------------------------------------')\n",
        "\n",
        "r60f = torch.arange(0, 60, dtype=torch.float)\n",
        "print(f'r60f = {r60f}')\n",
        "print()\n",
        "print(f'r60f.shape = {r60f.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20747a8a",
      "metadata": {
        "id": "20747a8a"
      },
      "source": [
        "## 1.4(a) Reshape a tensor with reshape()\n",
        "\n",
        "Now let's talk about reshaping a tensor. This requires some explanation. Even though a tensor can have multiple dimensions, you can think of the underlying data being stored as one logically contiguous blob of data (though not necessarily physically), with indexing based on the shape. Those with C or C++ experience shall understand this well). As such, it makes sense that you can look at the same tensor with different \"views\" of the same data.\n",
        "\n",
        "It may be confusing at first when you look at the indices, though it is helpful to think of it as a hierachical grouping, similar to how a physical address is a hierarchy fully specified by state, city, street, and number. In the example below, we simply group the numbers into a 3-level hierarchy -- we have 3 groups of 4 groups of 5 numbers.\n",
        "\n",
        "Another way to look at it is that the full index is a \"badge\" for the purpose of grouping and ordering. You can compare two badges lexicographically. e.g. index `[1,2,4]` < index `[1,3,2]`. With this understanding, reshaping a tensor does not change the lexicographical ordering of the underlying elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d125e8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d125e8a",
        "outputId": "2355190d-3c70-4dae-db2d-84c051dec199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r345 = tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "\n",
            "r345.shape = torch.Size([3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "r345 = r60.reshape(3, 4, 5)\n",
        "print(f'r345 = {r345}')\n",
        "print()\n",
        "print(f'r345.shape = {r345.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31e38f53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31e38f53",
        "outputId": "20b3abe5-ac61-47b4-b9dd-58e02ab5c267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2325 = tensor([[[[ 0,  1,  2,  3,  4],\n",
            "          [ 5,  6,  7,  8,  9]],\n",
            "\n",
            "         [[10, 11, 12, 13, 14],\n",
            "          [15, 16, 17, 18, 19]],\n",
            "\n",
            "         [[20, 21, 22, 23, 24],\n",
            "          [25, 26, 27, 28, 29]]],\n",
            "\n",
            "\n",
            "        [[[30, 31, 32, 33, 34],\n",
            "          [35, 36, 37, 38, 39]],\n",
            "\n",
            "         [[40, 41, 42, 43, 44],\n",
            "          [45, 46, 47, 48, 49]],\n",
            "\n",
            "         [[50, 51, 52, 53, 54],\n",
            "          [55, 56, 57, 58, 59]]]])\n",
            "\n",
            "torch.Size([2, 3, 2, 5])\n"
          ]
        }
      ],
      "source": [
        "r2325 = r345.reshape(2, 3, 2, 5)\n",
        "print(f'r2325 = {r2325}')\n",
        "print()\n",
        "print(r2325.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33067907",
      "metadata": {
        "id": "33067907"
      },
      "source": [
        "## 1.4(b) Reshape a tensor with view()\n",
        "\n",
        "Under certain condition, you can use `view()` instead of `reshape()`. `View()` is a more efficient version of `reshape()` when the underlying data is already known to be physically contiguous, or else it would fail. For the purpose of this exercise, we recommend `reshape()` over `view()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d0c7b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76d0c7b5",
        "outputId": "ee285a8b-878a-4b04-fcb2-7495e35c7f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r345v = tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "\n",
            "r345v.shape = torch.Size([3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "r345v = r60.view(3, 4, 5)\n",
        "print(f'r345v = {r345v}')\n",
        "print()\n",
        "print(f'r345v.shape = {r345v.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca65407d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca65407d",
        "outputId": "fb77c4bc-6e3e-4d02-d033-96013e084cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0,  1,  2,  3,  4],\n",
            "          [ 5,  6,  7,  8,  9]],\n",
            "\n",
            "         [[10, 11, 12, 13, 14],\n",
            "          [15, 16, 17, 18, 19]]],\n",
            "\n",
            "\n",
            "        [[[20, 21, 22, 23, 24],\n",
            "          [25, 26, 27, 28, 29]],\n",
            "\n",
            "         [[30, 31, 32, 33, 34],\n",
            "          [35, 36, 37, 38, 39]]],\n",
            "\n",
            "\n",
            "        [[[40, 41, 42, 43, 44],\n",
            "          [45, 46, 47, 48, 49]],\n",
            "\n",
            "         [[50, 51, 52, 53, 54],\n",
            "          [55, 56, 57, 58, 59]]]])\n",
            "\n",
            "r2325v.shape = torch.Size([3, 2, 2, 5])\n"
          ]
        }
      ],
      "source": [
        "r2325v = r345v.reshape(3, 2, 2, 5)\n",
        "print(r2325v)\n",
        "print()\n",
        "print(f'r2325v.shape = {r2325v.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7a2003a",
      "metadata": {
        "id": "a7a2003a"
      },
      "source": [
        "## 1.6 Transpose\n",
        "\n",
        "With a good understand of how the indices work, `transpose()` should be easy to understand. Note that `transpose()` is more than just changing the view of the tensor, because the underlying data may need to be reordered, as you can see by inspecting the flattened versions of the tensors before and after the transposition, as demonstrated below too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea3e0e3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea3e0e3c",
        "outputId": "a87e4f4b-1275-405b-f0ee-a31bb3472549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  5, 10, 15],\n",
            "         [ 1,  6, 11, 16],\n",
            "         [ 2,  7, 12, 17],\n",
            "         [ 3,  8, 13, 18],\n",
            "         [ 4,  9, 14, 19]],\n",
            "\n",
            "        [[20, 25, 30, 35],\n",
            "         [21, 26, 31, 36],\n",
            "         [22, 27, 32, 37],\n",
            "         [23, 28, 33, 38],\n",
            "         [24, 29, 34, 39]],\n",
            "\n",
            "        [[40, 45, 50, 55],\n",
            "         [41, 46, 51, 56],\n",
            "         [42, 47, 52, 57],\n",
            "         [43, 48, 53, 58],\n",
            "         [44, 49, 54, 59]]])\n",
            "\n",
            "torch.Size([3, 5, 4])\n"
          ]
        }
      ],
      "source": [
        "r345t = r345.transpose(1, 2)\n",
        "print(r345t)\n",
        "print()\n",
        "print(r345t.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40a7834c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40a7834c",
        "outputId": "341ac025-a530-4f4c-fe2f-999d0d81bbcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r345.flatten() = tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "        54, 55, 56, 57, 58, 59])\n",
            "----------------------------------------------------------------\n",
            "r345t.flatten() = tensor([ 0,  5, 10, 15,  1,  6, 11, 16,  2,  7, 12, 17,  3,  8, 13, 18,  4,  9,\n",
            "        14, 19, 20, 25, 30, 35, 21, 26, 31, 36, 22, 27, 32, 37, 23, 28, 33, 38,\n",
            "        24, 29, 34, 39, 40, 45, 50, 55, 41, 46, 51, 56, 42, 47, 52, 57, 43, 48,\n",
            "        53, 58, 44, 49, 54, 59])\n"
          ]
        }
      ],
      "source": [
        "print(f'r345.flatten() = {r345.flatten()}')\n",
        "print('----------------------------------------------------------------')\n",
        "print(f'r345t.flatten() = {r345t.flatten()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9322879e",
      "metadata": {
        "id": "9322879e"
      },
      "source": [
        "## 1.7 Squeeze and unsqueeze\n",
        "\n",
        "Squeezing is to remove a specific dimension of a tensor which has only one element in that dimension. Unsqueezing is to introduce a new dimension with only one element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f4f023",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7f4f023",
        "outputId": "e9e7ec1e-0a5c-4fce-c448-aaadbbed2dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r345 = tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "----------------------------------------------------------------\n",
            "r345.shape = torch.Size([3, 4, 5])\n",
            "----------------------------------------------------------------\n",
            "r3145.shape = torch.Size([3, 1, 4, 5])\n",
            "----------------------------------------------------------------\n",
            "r31415.shape = torch.Size([3, 1, 4, 1, 5])\n",
            "----------------------------------------------------------------\n",
            "r3415.shape = torch.Size([3, 4, 1, 5])\n",
            "----------------------------------------------------------------\n",
            "r3415 = tensor([[[[ 0,  1,  2,  3,  4]],\n",
            "\n",
            "         [[ 5,  6,  7,  8,  9]],\n",
            "\n",
            "         [[10, 11, 12, 13, 14]],\n",
            "\n",
            "         [[15, 16, 17, 18, 19]]],\n",
            "\n",
            "\n",
            "        [[[20, 21, 22, 23, 24]],\n",
            "\n",
            "         [[25, 26, 27, 28, 29]],\n",
            "\n",
            "         [[30, 31, 32, 33, 34]],\n",
            "\n",
            "         [[35, 36, 37, 38, 39]]],\n",
            "\n",
            "\n",
            "        [[[40, 41, 42, 43, 44]],\n",
            "\n",
            "         [[45, 46, 47, 48, 49]],\n",
            "\n",
            "         [[50, 51, 52, 53, 54]],\n",
            "\n",
            "         [[55, 56, 57, 58, 59]]]])\n"
          ]
        }
      ],
      "source": [
        "print(f'r345 = {r345}')\n",
        "print('----------------------------------------------------------------')\n",
        "print(f'r345.shape = {r345.shape}')\n",
        "print('----------------------------------------------------------------')\n",
        "r3145 = r345.unsqueeze(1)\n",
        "print(f'r3145.shape = {r3145.shape}')\n",
        "print('----------------------------------------------------------------')\n",
        "r31415 = r3145.unsqueeze(3)\n",
        "print(f'r31415.shape = {r31415.shape}')\n",
        "print('----------------------------------------------------------------')\n",
        "r3415 = r31415.squeeze(1)\n",
        "print(f'r3415.shape = {r3415.shape}')\n",
        "print('----------------------------------------------------------------')\n",
        "print(f'r3415 = {r3415}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2f0ac94",
      "metadata": {
        "id": "a2f0ac94"
      },
      "source": [
        "---\n",
        "\n",
        "# [Tutorial] Part 2 -- Basic PyTorch\n",
        "\n",
        "A Pytorch module (`nn.Module`) is the basic unit of computation out of which complex neural networks are built. Here we assume you are familiar with some of the basics of deep learning, namely the concept of the forward computation and the back-propagation. Behind the powerful PyTorch machinery is the automatic and dynamic construction of the computation graphs, which allows the framework to compute gradients automatically, facilitating both the forward computation and back-propagation.\n",
        "\n",
        "The computation graphs in PyTorch are rebuilt from scratch at every iteration.\n",
        "\n",
        "PyTorch provides some built-in modules that are standard across all applications, as well as the opportunity for you to build your own by simply building your own PyTorch modules on top of existing ones. Here's you'll need to be familiar with the following modules:\n",
        "\n",
        "```\n",
        "nn.Linear(X, Y)               # X, Y are the sizes of input/output features\n",
        "nn.ReLU()\n",
        "nn.Dropout(D)                 # D is the dropout fraction\n",
        "nn.LayerNorm(N)\n",
        "nn.Embedding(V, N)            # V is the size of the vocab\n",
        "```\n",
        "\n",
        "Most of these modules have trainable weights, but some don't (e.g. `nn.Dropout`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d91bc5e",
      "metadata": {
        "id": "9d91bc5e"
      },
      "source": [
        "# 2.1 PyTorch Module Example\n",
        "\n",
        "You can design your own custom PyTorch module by defining a Python class inheriting from `nn.Module`, and make sure you implement two functions: `__init__()` and `forward()`. The `__init__()` function defines how the module is constructed.\n",
        "\n",
        "You then instantiate a Python object of your custom module as usual. Let's name this object `o`. To perform the forward computation, you actually don't call the function `forward()`, but instead treat the object as a function, and call it. This may be confusing, but PyTorch actually look at the `forward()` function as only a\n",
        "specification on how to perform the forward computation. In fact, it will use the same specification to\n",
        "derive how to perform the back-propagation.\n",
        "\n",
        "Note that, for the purpose of this exercise you need to develop the habit of separating the _why_ from the _how_.\n",
        "\n",
        "The why question is: why is this neural network architected this particular way. Very often deep learning architectures go through iterations of evolutions as researchers understand more and more how they work.\n",
        "\n",
        "And the how question is: how to _how_ to implement a specific architecture. Let's take a look at an example.\n",
        "\n",
        "The following is a network that takes in `N` inputs, goes through a `N-by-M` fully-connected (FC) network, then another `M-by-N` fully-connected network, layer-normalization, dropout, another `N-by-K` network, and finally a softmax. It is actually not hard to translate what I just said to PyTorch module definition.\n",
        "\n",
        "```\n",
        "class SampleModule(nn.Module):\n",
        "\n",
        "    def __init__(self, N, M, K, dropout=0.1):\n",
        "        super(SampleModule, self).__init__()\n",
        "        self.N = N\n",
        "        self.M = M\n",
        "        self.K = K\n",
        "        self.FC1 = nn.Linear(N, M)\n",
        "        self.FC2 = nn.Linear(M, N)\n",
        "        self.layer_norm = nn.LayerNorm(N)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.FC3 = nn.Linear(N, K)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.FC1(x)\n",
        "        x = self.FC2(x)\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.FC3(x)\n",
        "        x = torch.softmax(x, -1)\n",
        "        return x\n",
        "```        \n",
        "\n",
        "And then you can instantiate the object like this:\n",
        "\n",
        "```\n",
        "sample_obj = SampleModule(60, 3, 10, 0.1)\n",
        "```\n",
        "\n",
        "And run `forward()` like this:\n",
        "\n",
        "```\n",
        "input = torch.arange(0, 60)\n",
        "print(f'input = {input}')\n",
        "\n",
        "output = sample_obj(sample_input)  # forward() is called under the hood\n",
        "print(f'output = {output}')\n",
        "```\n",
        "\n",
        "Here's something important to talk about.\n",
        "You can build PyTorch modules with pre-defined or custom-made modules. You must _name_ them in the `__init__()` function so that they can be properly registered so the PyTorch\n",
        "framework knows which parameters can be optimized. PyTorch wants to know about that upfront. In our\n",
        "example, we did just that.\n",
        "\n",
        "This is usually pretty straight-forward, with one exception, which we'll talk about shortly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6389e14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6389e14",
        "outputId": "064ab390-ed8a-449e-9d09-c806d316fc71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
            "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
            "        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
            "        42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54., 55.,\n",
            "        56., 57., 58., 59.])\n",
            "\n",
            "input.shape = torch.Size([60])\n",
            "----------------------------------------------------------------\n",
            "output = tensor([0.0681, 0.0508, 0.0886, 0.1109, 0.3116, 0.0851, 0.0663, 0.1174, 0.0413,\n",
            "        0.0598], grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "output.shape = torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "class ExampleModule(nn.Module):\n",
        "\n",
        "    def __init__(self, N, M, K, dropout=0.1):\n",
        "        super(ExampleModule, self).__init__()\n",
        "        self.N = N\n",
        "        self.M = M\n",
        "        self.K = K\n",
        "        self.FC1 = nn.Linear(N, M)\n",
        "        self.FC2 = nn.Linear(M, N)\n",
        "        self.layer_norm = nn.LayerNorm(N)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.FC3 = nn.Linear(N, K)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.FC1(x)\n",
        "        x = self.FC2(x)\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.FC3(x)\n",
        "        x = torch.softmax(x, -1)\n",
        "        return x\n",
        "\n",
        "sample_obj = ExampleModule(60, 3, 10, 0.1)  # instantiate a module\n",
        "\n",
        "input = torch.arange(0, 60, dtype=torch.float)\n",
        "print(f'input = {input}')\n",
        "print()\n",
        "print(f'input.shape = {input.shape}')\n",
        "print('----------------------------------------------------------------')\n",
        "output = sample_obj(input)  # forward() is called under the hood\n",
        "print(f'output = {output}')\n",
        "print()\n",
        "print(f'output.shape = {output.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "140fd05f",
      "metadata": {
        "id": "140fd05f"
      },
      "source": [
        "## 2.2 PyTorch ModuleList\n",
        "\n",
        "Let's you have a stack of layers whose total number is to be determined as an input parameter.\n",
        "Instead of putting them in a list, you should put them in a `nn.ModuleList()`.\n",
        "The reason is that the PyTorch framework needs to figure out the complete list of\n",
        "optimizable weights,\n",
        "by looking at the `__init__()` function only, and it cannot see them\n",
        "if you put them in a plain Python list.\n",
        "\n",
        "```\n",
        "class SampleWrong(nn.Module):\n",
        "    def __init__(self, N, K):\n",
        "        super(SampleWrong, self).__init__()\n",
        "        self.layers = [nn.Linear(N, N) for _ in range(K)]\n",
        "    def forward(self, x):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return x\n",
        "\n",
        "class SampleCorrect(nn.Module):\n",
        "    def __init__(self, N, K):\n",
        "        super(SampleCorrect, self).__init__()\n",
        "        self.layers = nn.ModuleList([nn.Linear(N, N) for _ in range(K)])\n",
        "    def forward(self, x):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return x\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "784f3bea",
      "metadata": {
        "id": "784f3bea"
      },
      "source": [
        "## 2.3 PyTorch Utilities -- `matmul()`\n",
        "\n",
        "`matmul()` is a flexible matrix multiplication utility optimized for DL-style matrix manipulation. See https://pytorch.org/docs/stable/generated/torch.matmul.html for more detail. In its simplest form, `matmul()` takes two matrices of dimensions `M-by-N` and `N-by-P` respectively, and return an `M-by-P` matrix that is the result of standard matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b52fd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01b52fd7",
        "outputId": "c0b855f4-e3b9-4fbd-8146-ff6c0f29338c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A = tensor([[0.5017, 0.9747, 0.7427, 0.2332, 0.5067],\n",
            "        [0.4452, 0.0975, 0.8920, 0.5081, 0.6053],\n",
            "        [0.2981, 0.2660, 0.5824, 0.6849, 0.6121]])\n",
            "A.shape = torch.Size([3, 5])\n",
            "----------------------------------------------------------------\n",
            "B = tensor([[0.2590, 0.9854, 0.4264],\n",
            "        [0.1938, 0.2661, 0.9922],\n",
            "        [0.5000, 0.4321, 0.2919],\n",
            "        [0.3689, 0.0789, 0.1027],\n",
            "        [0.7926, 0.9277, 0.9772]])\n",
            "B.shape = torch.Size([5, 3])\n",
            "----------------------------------------------------------------\n",
            "AB = tensor([[1.1779, 1.5632, 1.9169],\n",
            "        [1.2475, 1.4517, 1.1906],\n",
            "        [1.1579, 1.2382, 1.2296]])\n",
            "AB.shape = torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "A = torch.rand((3, 5))\n",
        "B = torch.rand((5, 3))\n",
        "print(f'A = {A}')\n",
        "print(f'A.shape = {A.shape}')\n",
        "print('----------------------------------------------------------------')\n",
        "print(f'B = {B}')\n",
        "print(f'B.shape = {B.shape}')\n",
        "print('----------------------------------------------------------------')\n",
        "AB = torch.matmul(A, B)\n",
        "print(f'AB = {AB}')\n",
        "print(f'AB.shape = {AB.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9f059c",
      "metadata": {
        "id": "5f9f059c"
      },
      "source": [
        "## 2.4 PyTorch Utilities -- Batches\n",
        "\n",
        "For deep learning, we often want to perform concurrent (or batched) operations, such as matrix multiplication, without iteration. Many of PyTorch functions, including `matmul()`, provides native support for that.\n",
        "\n",
        "Let's say instead of passing in two matrices of shapes `[M, N]` and `[N, P]`, you pass in two tensors of shapes `[B, M, N]` and `[B, N, P]`, representing a batch of `B` pairs of matrices to be multiplied. The result is a tensor of shape `[B, M, P]`.\n",
        "\n",
        "Batches are not restricted to a single dimension. For example, you can perform `matmul()` on two tensors of dimensions `[B, H, M, N]` and `[B, H, N, P]`. The result of the `matmul()` is a tensor of dimension `[B, H, M, P]`. You should interpret this as multiplying a 2-dimensional batch (of size `B` times `H`) of pairs of 2-dimensional matrices.\n",
        "\n",
        "Note that `matmul()` supports the multiplication of a single pair of tensors, a linear batch of tensors, and a 2D batch of tensors, and so on. How does it know what to do? Easy -- `matmul()` is intrinsically a 2D operation, and if you give it a pair of `K`-dimensional tensors, it will assume the last two dimensions are the matrix dimensions, and the first `K - 2` dimensions are the batches.\n",
        "\n",
        "In fact, experienced\n",
        "PyTorch practioners are so used to the concept of batching that they don't even mention it much, and thanks to\n",
        "great support from the PyTorch framework, batches are treated like a fixed prefix to most any PyTorch operations.\n",
        "On the other hand, this may trip up students who are seeing batched operations for the first time, and some may have issues with\n",
        "aligning or reconciling the shapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8c69c71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8c69c71",
        "outputId": "f2549776-88c4-4d20-a7ec-f03cb5cdd0c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AA.shape = torch.Size([12, 4, 3, 5])\n",
            "\n",
            "BB.shape = torch.Size([12, 4, 5, 3])\n",
            "\n",
            "AABB.shape = torch.Size([12, 4, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "AA = torch.rand((12, 4, 3, 5))\n",
        "BB = torch.rand((12, 4, 5, 3))\n",
        "print(f'AA.shape = {AA.shape}')\n",
        "print()\n",
        "print(f'BB.shape = {BB.shape}')\n",
        "print()\n",
        "AABB = torch.matmul(AA, BB)\n",
        "print(f'AABB.shape = {AABB.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ba0a5f8",
      "metadata": {
        "id": "6ba0a5f8"
      },
      "source": [
        "## 2.5 PyTorch Utilities -- Broadcasting\n",
        "\n",
        "PyTorch (actually NumPy) has an interesting (and useful) concept called broadcasting. Let's say you want to perform an element-wise tensor multiplication.\n",
        "\n",
        "One would normally expect that the shapes of the two tensors to match. For example, `[3, 4, 5, 6]` and `[3, 4, 5, 6]`. However, if the dimensions don't agree, but such that they are \"compatible\", the tensors can be\n",
        "virtually stretched or expanded in their dimensions so they are exact match.\n",
        "\n",
        "See https://numpy.org/doc/stable/user/basics.broadcasting.html for more information.\n",
        "\n",
        "For example, let's say you have a tensor of shape `[3, 4, 5, 5]` and another one of shape `[5, 5]` and you want to multiply them element-wise. What does it even mean? What are you trying to do? Well, perhaps this 4-dimensional tensor is really just a batch of `3-by-4` 2D matrices of shape `[5, 5]`, and you want to multiply each of such matrix with a _constant_ matrix that is of shape `[5, 5]`. Through the broadcasting semantics, you can conceptually think of the second matrix to have shape `[1, 1, 5, 5]`, and each of the dimension whose value is 1 is considered to be broadcasted (copied) as if they aare `[3, 4, 5, 5]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d65700",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68d65700",
        "outputId": "b16b5853-c10e-4fab-ae8b-9a70ef6ab4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r345 = tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "\n",
            "r345.shape = torch.Size([3, 4, 5])\n",
            "\n",
            "constant = tensor([100, 200, 300, 400, 500])\n",
            "\n",
            "constant.shape = torch.Size([5])\n",
            "\n",
            "r345 + constant = tensor([[[100, 201, 302, 403, 504],\n",
            "         [105, 206, 307, 408, 509],\n",
            "         [110, 211, 312, 413, 514],\n",
            "         [115, 216, 317, 418, 519]],\n",
            "\n",
            "        [[120, 221, 322, 423, 524],\n",
            "         [125, 226, 327, 428, 529],\n",
            "         [130, 231, 332, 433, 534],\n",
            "         [135, 236, 337, 438, 539]],\n",
            "\n",
            "        [[140, 241, 342, 443, 544],\n",
            "         [145, 246, 347, 448, 549],\n",
            "         [150, 251, 352, 453, 554],\n",
            "         [155, 256, 357, 458, 559]]])\n",
            "----------------------------------------------------------------\n",
            "constant_unsqueezed.shape = torch.Size([1, 1, 5])\n",
            "\n",
            "r345 + constant_unsqueezed = tensor([[[100, 201, 302, 403, 504],\n",
            "         [105, 206, 307, 408, 509],\n",
            "         [110, 211, 312, 413, 514],\n",
            "         [115, 216, 317, 418, 519]],\n",
            "\n",
            "        [[120, 221, 322, 423, 524],\n",
            "         [125, 226, 327, 428, 529],\n",
            "         [130, 231, 332, 433, 534],\n",
            "         [135, 236, 337, 438, 539]],\n",
            "\n",
            "        [[140, 241, 342, 443, 544],\n",
            "         [145, 246, 347, 448, 549],\n",
            "         [150, 251, 352, 453, 554],\n",
            "         [155, 256, 357, 458, 559]]])\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(f'r345 = {r345}')\n",
        "print()\n",
        "print(f'r345.shape = {r345.shape}')\n",
        "print()\n",
        "constant = torch.tensor([100, 200, 300, 400, 500])\n",
        "print(f'constant = {constant}')\n",
        "print()\n",
        "print(f'constant.shape = {constant.shape}')\n",
        "print()\n",
        "print(f'r345 + constant = {r345 + constant}')\n",
        "print('----------------------------------------------------------------')\n",
        "constant_unsqueezed = constant.unsqueeze(0).unsqueeze(0)\n",
        "print(f'constant_unsqueezed.shape = {constant_unsqueezed.shape}')\n",
        "print()\n",
        "print(f'r345 + constant_unsqueezed = {r345 + constant_unsqueezed}')\n",
        "print('----------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7526721",
      "metadata": {
        "id": "e7526721"
      },
      "source": [
        "---\n",
        "\n",
        "## 2.6 PyTorch batches\n",
        "\n",
        "PyTorch modules are typically designed to handle batches, i.e. to work on multiple inputs at the same time. The ability to handle a batch of input is essential to good GPU utilization and convergence during training. At inference time, if there is only one input, we simply use a batch size of one.\n",
        "\n",
        "Consider transformer in its original NLP usage, where the input is a list of `L` tokens (say in byte-pair encoding) of a vocabulary. The forward function should take a two-dimensional tensor, with shape `[B, L]`, where `B` is the batch size, and `L` is the number of tokens. Then, we need to make sure all the tensor manipulations support an additional dimension of batches.\n",
        "\n",
        "For example, in the sample module mentioned earlier, which conceptually works on a 1D tensor (of arbitrary length `L`).\n",
        "\n",
        "Without changing a single line of code, it actually can support batch mode, where you give it a\n",
        "tensor of shape `[B, L]` instead of just `[L]`. This is the case because each of the PyTorch modules `nn.Linear`, `nn.LayerNorm`, and `nn.Dropout` takes either a single 1D tensor (of shape `[L]`), or a batch of 1D tensors\n",
        "(of shape `[B, L]`). The call to `softmax()` works on the very last dimension of the tensor, which allows it to work either with a 1D tensor or a batch of 1D tensors.\n",
        "\n",
        "```\n",
        "class SampleModule(nn.Module):\n",
        "\n",
        "    def __init__(self, N, M, K, dropout=0.1):\n",
        "        super(SampleModule, self).__init__()\n",
        "        self.N = N\n",
        "        self.M = M\n",
        "        self.K = K\n",
        "        self.FC1 = nn.Linear(N, M)\n",
        "        self.FC2 = nn.Linear(M, N)\n",
        "        self.layer_norm = nn.LayerNorm(N)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.FC3 = nn.Linear(N, K)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.FC1(x)\n",
        "        x = self.FC2(x)\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.FC3(x)\n",
        "        x = torch.softmax(x, -1)  # note the significance of softmx on the last dimension (-1)\n",
        "        return x\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b5719a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53b5719a",
        "outputId": "2773657a-c575-4e67-b63f-cd3cfee4fc6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "tensor = tensor([0.5802, 0.2701, 0.6060])\n",
            "\n",
            "example(tensor) = tensor([0.1799, 0.1741, 0.1317, 0.0569, 0.1241, 0.1681, 0.1653],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "----------------------------------------------------------------\n",
            "batch_of_tensors = tensor([[0.9568, 0.5741, 0.5386],\n",
            "        [0.5342, 0.7660, 0.4938],\n",
            "        [0.9286, 0.7605, 0.1222],\n",
            "        [0.5000, 0.0756, 0.1161],\n",
            "        [0.5971, 0.6124, 0.4562],\n",
            "        [0.9752, 0.2314, 0.2905],\n",
            "        [0.4199, 0.5030, 0.4576],\n",
            "        [0.9502, 0.2888, 0.2385],\n",
            "        [0.5430, 0.8755, 0.6187],\n",
            "        [0.7694, 0.5968, 0.9261]])\n",
            "\n",
            "example(batch_of_tensors) = tensor([[0.1922, 0.1472, 0.1120, 0.0705, 0.1035, 0.1483, 0.2263],\n",
            "        [0.1864, 0.1630, 0.1234, 0.0621, 0.1157, 0.1600, 0.1894],\n",
            "        [0.1579, 0.1797, 0.1357, 0.0606, 0.1433, 0.1582, 0.1644],\n",
            "        [0.1573, 0.1992, 0.1531, 0.0463, 0.1420, 0.1867, 0.1154],\n",
            "        [0.1588, 0.1829, 0.1381, 0.0579, 0.1437, 0.1623, 0.1563],\n",
            "        [0.1451, 0.1229, 0.0977, 0.1089, 0.1039, 0.1111, 0.3104],\n",
            "        [0.1463, 0.1868, 0.1807, 0.0561, 0.0867, 0.2523, 0.0911],\n",
            "        [0.1779, 0.1769, 0.1339, 0.0556, 0.1261, 0.1701, 0.1595],\n",
            "        [0.1904, 0.1535, 0.1165, 0.0670, 0.1084, 0.1530, 0.2111],\n",
            "        [0.1934, 0.1408, 0.1076, 0.0741, 0.0986, 0.1436, 0.2418]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print('----------------------------------------------------------------')\n",
        "example = ExampleModule(3, 4, 7)\n",
        "tensor = torch.rand(3)\n",
        "print(f'tensor = {tensor}')\n",
        "print()\n",
        "print(f'example(tensor) = {example(tensor)}')\n",
        "print('----------------------------------------------------------------')\n",
        "batch_of_tensors = torch.rand(10, 3)\n",
        "print(f'batch_of_tensors = {batch_of_tensors}')\n",
        "print()\n",
        "example(batch_of_tensors)\n",
        "print(f'example(batch_of_tensors) = {example(batch_of_tensors)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1164dc0",
      "metadata": {
        "id": "f1164dc0"
      },
      "source": [
        "---\n",
        "\n",
        "## 2.7 PyTorch Embedding\n",
        "\n",
        "The embedding module, `nn.Embedding(V, D)`, is a pre-built module that allows for the mapping of a vocab-based token sequence into the embedding space. The vocab-based token sequence is just a sequence of `L` integers, ranging from `0` to `V-1`, where `V` is the size of the vocabulary.\n",
        "\n",
        "To be more precise, the input is a tensor of shape `[L]` with non-negative integers less than `V`.\n",
        "\n",
        "The output is a tensor of shape `[L, D]`, where each token in the vocabulary is embedded into a `D`-dimensional array of real numbers.\n",
        "\n",
        "Just like other pre-built PyTorch modules, `nn.Embedding` supports batches. Therefore, if the input is a tensor of shape `[B, L]`, it will return a tensor of shape `[B, L, D]`.\n",
        "\n",
        "In the following, we have a batch of two token sequences (5 tokens each, and each token is an integer between 0 and 99 inclusive). The weights of the embedding is undefined and you would get different results every time. In practice, we either initialize the embedding from pre-trained weights, or allow the weights to be optimized as part of the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b994c8b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b994c8b9",
        "outputId": "c865cd86-eaca-4d80-c827-58d0f61ece1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = tensor([[41, 31, 28, 14,  5],\n",
            "        [98,  2, 71,  8, 44]])\n",
            "\n",
            "input.shape = torch.Size([2, 5])\n",
            "----------------------------------------------------------------\n",
            "embedding V = 100, D = 8\n",
            "----------------------------------------------------------------\n",
            "output = tensor([[[-1.4683, -1.5218, -1.2173,  1.3267,  0.6552,  0.6860, -0.6832,\n",
            "           0.8930],\n",
            "         [-1.4766, -1.0946, -0.8658,  0.8368, -0.9401,  1.4285,  0.1983,\n",
            "          -2.3386],\n",
            "         [ 0.1635,  0.3051,  0.7243, -0.0879, -1.1320,  0.2265,  0.5291,\n",
            "           1.5444],\n",
            "         [-0.0931, -1.2083,  3.1685,  2.2975, -0.1413, -1.9954,  0.0353,\n",
            "          -0.6148],\n",
            "         [-0.7325,  1.6848,  0.4439, -0.6847, -0.7689,  1.9105, -0.9282,\n",
            "           0.7426]],\n",
            "\n",
            "        [[-2.0021, -0.2687, -0.7011, -0.9031, -1.2791, -0.4035, -0.6025,\n",
            "          -0.4698],\n",
            "         [-1.1589,  0.8676,  1.5684,  0.1834, -0.0581,  0.3220,  0.4669,\n",
            "           0.0144],\n",
            "         [ 0.8413, -0.6978,  1.6602, -0.1676, -1.4809, -0.1712,  0.2488,\n",
            "          -0.0217],\n",
            "         [ 0.5041,  0.9985,  0.0367,  0.2298, -1.9846, -1.2512,  0.6219,\n",
            "           0.6581],\n",
            "         [-0.5694, -1.2073,  0.7853,  0.0824,  1.6416, -0.5689,  0.3489,\n",
            "          -1.1777]]], grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "output.shape = torch.Size([2, 5, 8])\n"
          ]
        }
      ],
      "source": [
        "input = torch.tensor([[41, 31, 28, 14, 5], [98, 2, 71, 8, 44]])\n",
        "print(f'input = {input}')\n",
        "print()\n",
        "print(f'input.shape = {input.shape}')\n",
        "print('----------------------------------------------------------------')\n",
        "\n",
        "V = 100\n",
        "D = 8\n",
        "embedding = nn.Embedding(V, D)\n",
        "print(f'embedding V = {V}, D = {D}')\n",
        "print('----------------------------------------------------------------')\n",
        "output = embedding(input)\n",
        "print(f'output = {output}')\n",
        "print()\n",
        "print(f'output.shape = {output.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de694627",
      "metadata": {
        "id": "de694627"
      },
      "source": [
        "---\n",
        "\n",
        "# [Tutorial] Part 3 -- Transformer Explainer\n",
        "\n",
        "Now we have all the tools to implement transformer, as shown in the following diagram (from the paper \"Attention is All You Need\" https://arxiv.org/pdf/1706.03762.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3dd7b7",
      "metadata": {
        "id": "ce3dd7b7"
      },
      "source": [
        "![Screenshot%202023-10-04%20at%203.59.01%20PM.png](attachment:Screenshot%202023-10-04%20at%203.59.01%20PM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838de88d",
      "metadata": {
        "id": "838de88d"
      },
      "source": [
        "---\n",
        "\n",
        "## 3.1 Transformer by Example -- Inference\n",
        "\n",
        "Before we start, let's explain how transformer works by way of an example. The `inputs` and `outputs` are batches of tokens that are already encoded (such as using byte-pair encoding) from the original text, say, \"it is a beautiful day!\", and we are using the transformer to translate to French \"c'est une belle journe\":\n",
        "\n",
        "```\n",
        "it is a beautiful day! --> c'est une belle journe!\n",
        "```\n",
        "\n",
        "The first half is called the source (or `input` in the diagram), and the second half is called the target (or `output` in the diagram).\n",
        "\n",
        "As we mentioned before, the transformer is designed to handle a batch of input/output pairs at the same time, which is important for training. So we're looking at something like this:\n",
        "\n",
        "\n",
        "```\n",
        "it is a beautiful day! --> c'est une belle journe!\n",
        "do you like flowers?   --> aimes-tu les fleurs?\n",
        "```\n",
        "\n",
        "And their encodings could be:\n",
        "\n",
        "```\n",
        "[32, 12, 84, 34, 108, 15, 77, 1] --> [201, 104, 154, 123, 75, 1]\n",
        "[10, 14, 17, 92, 44, 1]          --> [107, 34, 55, 678, 23, 54, 97, 65, 1]\n",
        "```\n",
        "\n",
        "Here, we are going to use `1` to represent the start-of-sentence token (`<s>`), and `2` to represent the end-of-sentence token (`</s>`). This is an arbitrary decision and part of whatever the scheme the researchers chose to use.\n",
        "\n",
        "Moreover, we want the sentences to be padded with `0` to represent the padding token, so all source sequences have the same length (9 in our case), and all target sequences have the same length (10 in our case):\n",
        "\n",
        "\n",
        "```\n",
        "[2, 32, 12, 84, 34, 108, 15, 77, 1] --> [2, 201, 104, 154, 123, 75, 1, 0, 0, 0]\n",
        "[2, 10, 14, 17, 92, 44, 1, 0, 0]    --> [2, 107, 34, 55, 678, 23, 54, 97, 65, 1]\n",
        "```\n",
        "\n",
        "Now, it is clear the input is a tensor with shape `[B, Ls]`, and the output is a tensor with shape\n",
        "`[B, Lt]`, where `Ls` and `Lt` are the lengths of the source and target sequences. `Ls` and `Lt` don't need to be\n",
        "the same, but both must be no larger than `maxL`, which is used in the positional encoding modules -- this is just so that we can pre-build the positional encoder once and for all in the constructor.\n",
        "\n",
        "Now let's look at the two halves of the transformer separately. The left half is the encoder stack, and the right half is the decoder stack. The job of the encoder stack is to encode the input sequences into an embedding representation and repeatedly transform it. You should be familiar with the notion of embedding, which is nothing but a `D`-dimensional vector. If you look at it from the perspective of how the input tensor flows through\n",
        "the stack, it looks like this:\n",
        "\n",
        "```\n",
        "[B, Ls] --> [B, Ls, D] --> [B, Ls, D] --> ... --> [B, Ls, D]\n",
        "```\n",
        "\n",
        "Let's say we choose the embedding dimension to be 4, and there are 5 encoders on the stack (i.e. `Nx = 5`), the sequence for our example would be:\n",
        "\n",
        "```\n",
        "[2, 9] --> [2, 9, 4] --> [2, 9, 4] --> [2, 9, 4] --> [2, 9, 4] --> [2, 9, 4] --> [2, 9, 4]\n",
        "source     initial       encoder #1    encoder #2    encoder #3    encoder #4    encoder #5\n",
        "           embedding                                                             ==========\n",
        "                                                                                 final encoder output\n",
        "```\n",
        "\n",
        "Note that after the initial embedding, the tensor of shape `[B, Lt, D]` got repeatedly \"transformed\" to soak in more contextual information. You can think of the output of the last encoder to be the final words of the encoder stack. This will be passed to the decoder via the arrow depicted in the diagram. Let this tensor be called `C`\n",
        "(of shape `[B, Ls, D]`).\n",
        "\n",
        "At inference time, we are asked to predict one token at a time. What does this mean?\n",
        "\n",
        "Let's now look at the decoder stack, which is the right side of the transformer architecture depicted in the\n",
        "diagram. We are going to predict one token at a time, given the start token `<s>` and the context `C` which is the output of the encoder stack, and it encapsulates all the information from the source sentence in a highly\n",
        "usable way. Note that `C` (again, with shape `[B, Ls, D]`) will remain unchanged throughout the decoding process. Let's consider the first example, `it is a beautiful day!`. Conceptually, we want to do this:\n",
        "\n",
        "```\n",
        "    \"C\" + <s>                          --> c'est\n",
        "                                           -----\n",
        "    \"C\" + <s> c'est                    --> c'est une\n",
        "                                                 ---\n",
        "    \"C\" + <s> c'est une                --> c'est une belle\n",
        "                                                     -----\n",
        "    \"C\" + <s> c'est une belle          --> c'est une belle jour\n",
        "                                                           ----\n",
        "    \"C\" + <s> c'est une belle jour     --> c'est une belle journe\n",
        "                                                               ---\n",
        "    \"C\" + <s> c'est une belle journe  --> c'est une belle journe!\n",
        "                                                                  -\n",
        "    \"C\" + <s> c'est une belle journe! --> c'est une belle journe! </s>\n",
        "                                                                    ----\n",
        "=======   ============================\n",
        "  final   target\n",
        "encoder   tensor\n",
        " tensor\n",
        "```\n",
        "\n",
        "Of course, in reality we are working with the target tensor of numbers whose shape is `[B, Lt, D]` instead of English or French words, but the idea is the same.\n",
        "\n",
        "Starting with a target tensor with only the `<s>` token, we compute the next output token, and then expand the target tensor (depicted as `Outputs (shifted right)` in the diagram) and repeat the process. When do we stop? When the next output token generated is `</s>`, or when the target tensor grows to `maxL` (in which case we run out of\n",
        "room and cannot continue). In our example, we terminate after 7 passes, and then you pad the output with the\n",
        "padding token `0`.\n",
        "\n",
        "Like the encoder, the decoder repeatedly \"transforms\" the tensor during each pass.\n",
        "\n",
        "```\n",
        "[B, Lt] --> [B, Lt, D] --> [B, Lt, D] --> ... --> [B, Lt, D]\n",
        "```\n",
        "\n",
        "In our example,\n",
        "\n",
        "```\n",
        "[2, 10] --> [2, 10, 4] --> [2, 10, 4] --> [2, 10, 4] --> [2, 10, 4] --> [2, 10, 4] --> [2, 10, 4]\n",
        "target      initial        decoder #1     decoder #2     decoder #3     decoder #4     decoder #5\n",
        "            embedding                                                                  ==========\n",
        "                                                                                       final decoder output\n",
        "```\n",
        "\n",
        "Note that the final decoder output is a tensor of shape `[B, Lt, D]`. How does this turn into the next token?\n",
        "\n",
        "Well, it turns out there are two more modules, a linear module and a softmax module, to turn the embeddings to actual probabilities:\n",
        "\n",
        "```\n",
        "[B, Lt, D] --> linear --> [B, Lt, Vt] --> softmax --> [B, Lt, Vt]\n",
        "                                                      ===========\n",
        "                                                      probabilities\n",
        "```\n",
        "\n",
        "Let's focus on one translation, from \"it is a beautiful day!\" to \"c'est une belle journe!\"\n",
        "The output of the decoder stack is actually a tensor of shape `[Lt, D]`. Think of it as an embedding for\n",
        "each of the output tokens. Each of the output token is represented by a `D`-dimensional embedding.\n",
        "The job of the linear module is to compute an unnormalized score for each word in the vocabulary.\n",
        "\n",
        "For example, let's say the embedding for the first output token is `[0.23, 0.43, 0.12, -0.14]` (we\n",
        "assume `D = 4`). Then, the linear module, which is fully connected, provides a score for each of the `Vt`\n",
        "words in the vocabulary (for example, `Vt` could be 30000).\n",
        "\n",
        "```\n",
        "[0.27, 0.09, 0.01, -1.02, 5.43, ..., 0.73]  # a total of Vt dimensions\n",
        "```\n",
        "\n",
        "Then, we'll perform a softmax, which converts the unnormalized score into normalized probabilities:\n",
        "\n",
        "\n",
        "```\n",
        "    [0.27, 0.09, 0.01, -1.02, 5.43, ..., 0.73]   # unnormalized scores (Vt dimensions)\n",
        "--> [0.02, 0.01, 0.004,  0.001, 0.77, ..., 0.12] # normalized probabilities (Vt dimensions)\n",
        "```\n",
        "\n",
        "In the simplest scheme, we would then pick out the index with the highest probability, which in this\n",
        "case is 0.77, at index 201, corresponding to the entry for `c'est`. That's it!\n",
        "\n",
        "In summary, for inference, we start by computing the context tensor `C` (of shape `[B, Ls, D]`)\n",
        "computed by decoding the source sequences, and then iteratively compute the target sequence, starting\n",
        "with the `<s>` token, and compute the next tokens one at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c000107c",
      "metadata": {
        "id": "c000107c"
      },
      "source": [
        "---\n",
        "\n",
        "## 3.2 Transformer by Example -- Training\n",
        "\n",
        "Transformer inference is done one-token at a time, so if you have 1000 tokens in the sentence, we will generate each one of the 1000 tokens one after the another.\n",
        "\n",
        "Training, on the other hand, is done in a single pass! This is actually quite amazing.\n",
        "\n",
        "A key innovation (which pre-dated transformer) is \"teacher forcing\". While we are still trying to predict the next token, once it is predicted, regardless of the prediction, we'll discard it and use the next correct token for the next prediction.\n",
        "\n",
        "Let's consider the `it is a beautiful day!` example. Let's say the first word predicted\n",
        "is `c'est` which is correct, but the next word is incorrectly predicted as `fleurs` instead of the correct\n",
        "answer `une`. For inference, we have no choice but to use `<s> c'est fleurs` to predict the next word, which can lead to some unexpectedly weird translation, and in fact may diverge greatly from what we expect.\n",
        "\n",
        "Instead, during training, we shall use `<s> c'est une` to predict the next token even though we mistakenly predicted `<s> c'est fleurs`. This is teacher forcing, and allows us to train in a more manageble way.\n",
        "\n",
        "Moreover, with teacher forcing, you can just give the whole answer to the student ahead of time, and just ask her not to peek ahead!\n",
        "\n",
        "```\n",
        "    \"C\" + <s> c'est une belle journe! --> c'est une belle journe! </s>\n",
        "          ===                              -----\n",
        "    \"C\" + <s> c'est une belle journe! --> c'est une belle journe! </s>\n",
        "          =========                              ---\n",
        "    \"C\" + <s> c'est une belle journe! --> c'est une belle journe! </s>\n",
        "          =============                              -----\n",
        "    \"C\" + <s> c'est une belle journe! --> c'est une belle journe! </s>\n",
        "          ===================                              ----\n",
        "    \"C\" + <s> c'est une belle journe! --> c'est une belle journe! </s>\n",
        "          ========================                             ---\n",
        "    \"C\" + <s> c'est une belle journe! --> c'est une belle journe! </s>\n",
        "          ===========================                             -\n",
        "    \"C\" + <s> c'est une belle journe! --> c'est une belle journe! </s>\n",
        "          ============================                              ----\n",
        "```\n",
        "\n",
        "Think of it as you need to predict a total of `Lt` tokens (7 in this case). To predict the first token,\n",
        "you are only allowed to see the context `C` and the first source token (`<s>`).\n",
        "\n",
        "To predict the second token, you are only allowed to see the context `C` and the first two source tokens\n",
        "(`<s> c'est`).\n",
        "\n",
        "To predict the third token, you are only allowed to see the context `C` and the first three source tokens\n",
        "(`<s> c'est une belle`).\n",
        "\n",
        "And so on.\n",
        "\n",
        "Unlike inference where we keep updating the target tensor as we get new predictions, during training,\n",
        "the source and target tensors are known and unchanged throughout! The only requirement is that when we\n",
        "are predicting the `kth` token, we are only allowed to look at the first `k` target tokens, and the entire\n",
        "context tensor `C` (which fully captures the source tensor). This essentially is identical to seeing the\n",
        "correction of what have been predicted so far.\n",
        "\n",
        "Teacher forcing allows for the clever trick of concurrent prediction of all tokens simultaneously, and\n",
        "this is done with masking, which we'll talk about during the implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6ed5c7f",
      "metadata": {
        "id": "b6ed5c7f"
      },
      "source": [
        "---\n",
        "\n",
        "## 3.3 The Attention Mechanism\n",
        "\n",
        "The attention mechanism (\"multi-head attention\") is the key mathematical concept that allow for the transformation of the tensors. The attention mechanism shows up three times in the diagram depiction, once in the encoder\n",
        "on the left, and twice in the decoder on the right. The bottom two of them are self-attentions, and the upper one is a cross-attention.\n",
        "\n",
        "Conceptually, for the attention mechanism to work, there is a query tensor (`Q`), a\n",
        "key tensor (`K`), and a value tensor (`V`). This is analogous to search query retrieval -- you search for something with a query (question), and the query is matched with the index or key of the documents, and finally you retrieve the content of the documents.\n",
        "\n",
        "The self-attention, where `Q`, `K`, and `V` are the exact same thing, is used in both the encoder and decoder. What is it? Think of it as a kind of collective\n",
        "group introspection. You have a tensor of a certain length, say `L`. Think of each element as a person, and together they form a group. Each person is making up a query based on themelves, and each person is also making up a key based on themselves. Then everyone is asking everyone else if they are a match by comparing the query and the key, measured in the form of a score. The scores are then normalized, and then each person becomes the weighted average of the values of the people they matched, weighting by the normalized scores.\n",
        "\n",
        "Self-attention is made infinitely more interesting when the query, key, and value are not the tensor per-se, but a trainable transformation of the embedding. For example, say each \"person\" is embedded in 4 dimensions:\n",
        "\n",
        "```\n",
        "[0.3, 0.4, 0.2, -0.9]\n",
        "```\n",
        "\n",
        "We would have three fully-connected, trainable `4-by-4` transformations to take the embedding to the query, key, and value:\n",
        "\n",
        "\n",
        "```\n",
        "[0.3, 0.4, 0.2, -0.9] --> W_q --> [0.2, 0.7, 0.3, -0.5]  # query\n",
        "[0.3, 0.4, 0.2, -0.9] --> W_k --> [0.1, -0.2, 0.0, 0.3]  # key\n",
        "[0.3, 0.4, 0.2, -0.9] --> W_v --> [0.7, 0.4, -0.1, 0.8]  # value\n",
        "```\n",
        "\n",
        "It may be instructive to think of the self-attention module as a kind of inner \"enlightenment\" within itself -- improving and enriching each individual based on the context of the entire group.\n",
        "\n",
        "Cross-attention, which follows self-attention in the decoder module, works similarly. In fact, the mathematics\n",
        "are the same, but the inputs are different. Instead of using the same tensor as `Q`, `K`, and `V`, notice `Q` is from the target tensor, and `K` and `V` are the source context tensor (the very last one). What is going on?\n",
        "\n",
        "Think of this as a cross-group matching, like dating. Think of the target tensor as a group of girls (there are `Lt` of them), and the source tensor as a group of guys (there are `Ls` of them). Note that this is for illustrative purpose only, reversing the gender works just as well.\n",
        "\n",
        "Each of the `Lt` girls in the first group makes up a query, and each of the `Ls` guys in the second group provides an index and his value. Then they match, and extract the values. At the end, the output of the cross-attention is the weighted average of the values of the guys based on how well the queries made by the girls match the indices made by the guys. Like in the case of self-attention, we don't use the embeddings straight up, but a trainable transformations of the embeddings with `W_q`, `W_k`, and `W_v`, which are trainable modules.\n",
        "\n",
        "Moreover, the output of the cross attention has the same dimension as that of the query. We start with a tensor of shape `[B, Lt, D]`, and end with a tensor of shape `[B, Lt, D]`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}